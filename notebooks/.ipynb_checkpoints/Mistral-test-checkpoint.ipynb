{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8360ef2e-2ebf-46d4-a517-3010c85b9214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: C:\\Users\\flore\\Dev_Workspace\\ai-learning\\.venv\\Scripts\\python.exe\n",
      "cuda: True\n",
      "gpu: NVIDIA GeForce RTX 5090 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import sys, torch\n",
    "print(\"python:\", sys.executable)\n",
    "print(\"cuda:\", torch.cuda.is_available())\n",
    "print(\"gpu:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"no gpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4425f577-194c-4564-bc0c-c185dc86a7cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Une GPU, ou Graphics Processing Unit, est une unité de traitement spécialisée conçue pour traiter rapidement et efficacement les calculs graphiques et visuels complexes. Contrairement aux CPUs (Central Processing Units) qui sont conçues pour traiter une grande variété de tâches, une GPU est optimisée pour les calculs graphiques et permet d'effectuer en parallèle de nombreuses opérations simples sur de grandes données. Cela permet de rendre en temps réel des images et des vidéos en 3D très détaillées et fluides, ce qui est essentiel dans les domaines tels que le jeu vidéo, la simulation physique, la création de contenu multimédia et les applications scientifiques."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from threading import Thread\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TextIteratorStreamer\n",
    "from IPython.display import clear_output, display, Markdown\n",
    "\n",
    "model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,  # ou torch.float16\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"Réponds uniquement en français. Explique ce qu'est un GPU.\"}]\n",
    "\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "device = next(model.parameters()).device\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "streamer = TextIteratorStreamer(\n",
    "    tokenizer,\n",
    "    skip_special_tokens=True,\n",
    "    skip_prompt=True,\n",
    ")\n",
    "\n",
    "gen_kwargs = dict(\n",
    "    **inputs,\n",
    "    streamer=streamer,\n",
    "    max_new_tokens=512,\n",
    "    temperature=0.2,\n",
    "    top_p=0.9,\n",
    "    do_sample=True,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "\n",
    "t = Thread(target=model.generate, kwargs=gen_kwargs)\n",
    "t.start()\n",
    "\n",
    "text = \"\"\n",
    "for chunk in streamer:\n",
    "    text += chunk\n",
    "    clear_output(wait=True)\n",
    "    display(Markdown(text))\n",
    "\n",
    "t.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ba0c9e-d38e-4120-b73c-a356b7c7411d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI Learning",
   "language": "python",
   "name": "ai-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
